{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ccaa05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce0a3743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('reviews_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10c79526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Preprocessing\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "df['ReviewContent'] = df['ReviewContent'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d7619f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\arjun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\arjun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "df['ReviewContent'] = df['ReviewContent'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30368286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\arjun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "df['ReviewContent'] = df['ReviewContent'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbf29c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['ReviewContent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d91a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "df['Category_encoded'] = label_encoder.fit_transform(df['Category'])\n",
    "df['Generation_encoded'] = label_encoder.fit_transform(df['Generation'])\n",
    "df['Sentiment_encoded'] = label_encoder.fit_transform(df['Sentiment'])\n",
    "df['Country_encoded'] = label_encoder.fit_transform(df['Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adf9cfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets with stratified sampling\n",
    "X = tfidf_matrix\n",
    "y = df['Sentiment_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85f6a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "010a46ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Parameters (SVM): {'svc__kernel': 'rbf', 'svc__gamma': 'scale', 'svc__C': 10}\n",
      "Accuracy (SVM): 0.7026383406568854\n",
      "Classification Report (SVM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.08      0.14       125\n",
      "           1       0.10      0.02      0.03        53\n",
      "           2       0.50      0.15      0.24       117\n",
      "           3       0.72      0.95      0.82       698\n",
      "\n",
      "    accuracy                           0.70       993\n",
      "   macro avg       0.44      0.30      0.31       993\n",
      "weighted avg       0.63      0.70      0.62       993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the pipeline with SMOTE and SVM\n",
    "pipeline_svm = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('svc', SVC())\n",
    "])\n",
    "\n",
    "# Define parameters for hyperparameter tuning\n",
    "param_grid_svm = {\n",
    "    'svc__C': [0.1, 1, 10, 100],\n",
    "    'svc__gamma': ['scale', 'auto'],\n",
    "    'svc__kernel': ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "svm_random_search = RandomizedSearchCV(pipeline_svm, param_distributions=param_grid_svm, n_iter=20, scoring='accuracy', cv=5, verbose=1, random_state=42)\n",
    "svm_random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and evaluate on test set\n",
    "best_svm = svm_random_search.best_estimator_\n",
    "y_pred_svm = best_svm.predict(X_test)\n",
    "\n",
    "# Print best parameters and classification report\n",
    "print(\"Best Parameters (SVM):\", svm_random_search.best_params_)\n",
    "print(\"Accuracy (SVM):\", svm_random_search.best_score_)\n",
    "print(\"Classification Report (SVM):\")\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96e0c35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arjun\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "250 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "152 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\arjun\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\arjun\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\arjun\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\arjun\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "98 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\arjun\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\arjun\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\arjun\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\arjun\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\arjun\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [0.70306472 0.70738158        nan        nan 0.70306472 0.70608755\n",
      " 0.71429396        nan 0.71170217 0.70954048        nan        nan\n",
      "        nan 0.70306472 0.71515882 0.70306472 0.71126834        nan\n",
      " 0.70565465 0.71083731        nan        nan 0.70651672 0.71515603\n",
      " 0.71040534 0.70306472        nan 0.70694869 0.71083451 0.70694869\n",
      "        nan 0.71299713        nan        nan        nan 0.71342724\n",
      " 0.71213413 0.70608662 0.70436062 0.7142921         nan        nan\n",
      "        nan        nan 0.70867748 0.70608569        nan        nan\n",
      " 0.70867748        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.70694869        nan 0.70608755        nan\n",
      " 0.71602182 0.71342817 0.71083544 0.71040255        nan        nan\n",
      "        nan 0.70954048 0.7151551         nan        nan 0.71040348\n",
      " 0.71170124 0.70997244        nan        nan        nan 0.71472313\n",
      "        nan        nan        nan        nan 0.70694869 0.70392865\n",
      " 0.71731493 0.70306565        nan 0.70694869        nan        nan\n",
      " 0.70306472        nan 0.70392865        nan        nan 0.70306472\n",
      "        nan        nan        nan 0.70565558]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (Random Forest): {'n_estimators': 2000, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 100, 'bootstrap': False}\n",
      "Accuracy (Random Forest): 0.7173149251508155\n",
      "Classification Report (Random Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       125\n",
      "           1       0.00      0.00      0.00        53\n",
      "           2       0.65      0.21      0.31       117\n",
      "           3       0.72      0.98      0.83       698\n",
      "\n",
      "    accuracy                           0.71       993\n",
      "   macro avg       0.34      0.30      0.29       993\n",
      "weighted avg       0.58      0.71      0.62       993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define parameters for hyperparameter tuning\n",
    "param_grid_rf = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "rf_random_search = RandomizedSearchCV(rf_model, param_distributions=param_grid_rf, n_iter=100, scoring='accuracy', cv=5, verbose=1, random_state=42, n_jobs=-1)\n",
    "rf_random_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best model and evaluate on test set\n",
    "best_rf = rf_random_search.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "# Print best parameters and classification report\n",
    "print(\"Best Parameters (Random Forest):\", rf_random_search.best_params_)\n",
    "print(\"Accuracy (Random Forest):\", rf_random_search.best_score_)\n",
    "print(\"Classification Report (Random Forest):\")\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad0448e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Parameters (XGBoost): {'subsample': 0.9, 'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.05, 'colsample_bytree': 0.5}\n",
      "Accuracy (XGBoost): 0.7142855812914277\n",
      "Classification Report (XGBoost):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.05      0.08       125\n",
      "           1       0.00      0.00      0.00        53\n",
      "           2       0.60      0.21      0.31       117\n",
      "           3       0.73      0.97      0.83       698\n",
      "\n",
      "    accuracy                           0.71       993\n",
      "   macro avg       0.42      0.31      0.31       993\n",
      "weighted avg       0.63      0.71      0.63       993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Convert data to DMatrix format for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Define parameters for XGBoost\n",
    "param_grid_xgb = {\n",
    "    'max_depth': [3, 4, 5, 6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'colsample_bytree': [0.3, 0.4, 0.5, 0.7, 0.8, 1.0],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV with XGBoost\n",
    "xgb_random_search = RandomizedSearchCV(estimator=xgb.XGBClassifier(objective=\"multi:softmax\", num_class=4, seed=42),\n",
    "                                       param_distributions=param_grid_xgb, n_iter=50,\n",
    "                                       scoring='accuracy', n_jobs=-1, cv=5, verbose=1, random_state=42)\n",
    "xgb_random_search.fit(X_train, y_train_resampled)\n",
    "\n",
    "# Get the best model and evaluate on test set\n",
    "best_xgb = xgb_random_search.best_estimator_\n",
    "y_pred_xgb = best_xgb.predict(X_test)\n",
    "\n",
    "# Print best parameters and classification report\n",
    "print(\"Best Parameters (XGBoost):\", xgb_random_search.best_params_)\n",
    "print(\"Accuracy (XGBoost):\", xgb_random_search.best_score_)\n",
    "print(\"Classification Report (XGBoost):\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e85d133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Naive Bayes):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       125\n",
      "           1       0.00      0.00      0.00        53\n",
      "           2       0.00      0.00      0.00       117\n",
      "           3       0.70      1.00      0.83       698\n",
      "\n",
      "    accuracy                           0.70       993\n",
      "   macro avg       0.18      0.25      0.21       993\n",
      "weighted avg       0.49      0.70      0.58       993\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arjun\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\arjun\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\arjun\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Initialize Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# No hyperparameter tuning for Naive Bayes, just fit and predict\n",
    "nb_model.fit(X_train, y_train)\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report (Naive Bayes):\")\n",
    "print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1295e993",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Best Parameters: {'kernel': 'rbf', 'gamma': 'scale', 'class_weight': None, 'C': 100}\n",
      "Accuracy: 0.72\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.10      0.16       125\n",
      "           1       0.12      0.02      0.03        53\n",
      "           2       0.64      0.21      0.32       117\n",
      "           3       0.73      0.96      0.83       698\n",
      "\n",
      "    accuracy                           0.72       993\n",
      "   macro avg       0.49      0.32      0.34       993\n",
      "weighted avg       0.66      0.72      0.64       993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'class_weight': ['balanced', None]  # Try both balanced and None\n",
    "}\n",
    "\n",
    "# Initialize SVC classifier\n",
    "svc = SVC()\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=svc, param_distributions=param_grid, scoring='accuracy', \n",
    "                                   cv=5, n_iter=25, random_state=42, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and estimator\n",
    "best_params = random_search.best_params_\n",
    "best_estimator = random_search.best_estimator_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2f22278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Parameters (Random Forest): {'n_estimators': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 40, 'class_weight': {0: 1.9891826923076923, 1: 4.675141242937853, 2: 2.121794871794872, 3: 0.3556080790717662}, 'bootstrap': True}\n",
      "Accuracy (Random Forest): 0.73\n",
      "Classification Report (Random Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.10      0.17       125\n",
      "           1       0.25      0.02      0.04        53\n",
      "           2       0.70      0.33      0.45       117\n",
      "           3       0.74      0.97      0.84       698\n",
      "\n",
      "    accuracy                           0.73       993\n",
      "   macro avg       0.54      0.36      0.37       993\n",
      "weighted avg       0.68      0.73      0.67       993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming the data is preprocessed and loaded into the DataFrame df\n",
    "\n",
    "# Shuffle the dataset\n",
    "df = shuffle(df, random_state=42)\n",
    "\n",
    "# Define features and target variable\n",
    "X = df['ReviewContent']\n",
    "y = df['Sentiment_encoded']\n",
    "\n",
    "# Stratified split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
    "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [10, 20, 30, 40, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False],\n",
    "    'class_weight': [class_weights_dict, 'balanced', None]\n",
    "}\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search_rf = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, scoring='accuracy', \n",
    "                                      cv=5, n_iter=50, random_state=42, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search_rf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Best parameters and estimator\n",
    "best_params_rf = random_search_rf.best_params_\n",
    "best_estimator_rf = random_search_rf.best_estimator_\n",
    "\n",
    "print(f\"Best Parameters (Random Forest): {best_params_rf}\")\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_rf = best_estimator_rf.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Accuracy (Random Forest): {accuracy_rf:.2f}\")\n",
    "\n",
    "print(\"Classification Report (Random Forest):\")\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bfbef1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arjun\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:18:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (XGBoost): {'subsample': 0.6, 'scale_pos_weight': 4.675141242937853, 'objective': 'multi:softmax', 'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.01, 'colsample_bytree': 0.8}\n",
      "Accuracy (XGBoost): 0.70\n",
      "Classification Report (XGBoost):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.01      0.02       125\n",
      "           1       0.00      0.00      0.00        53\n",
      "           2       0.50      0.11      0.18       117\n",
      "           3       0.71      0.98      0.83       698\n",
      "\n",
      "    accuracy                           0.70       993\n",
      "   macro avg       0.34      0.28      0.26       993\n",
      "weighted avg       0.58      0.70      0.60       993\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arjun\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\arjun\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\arjun\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming the data is preprocessed and loaded into the DataFrame df\n",
    "\n",
    "# Shuffle the dataset\n",
    "df = shuffle(df, random_state=42)\n",
    "\n",
    "# Define features and target variable\n",
    "X = df['ReviewContent']\n",
    "y = df['Sentiment_encoded']\n",
    "\n",
    "# Stratified split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
    "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'scale_pos_weight': [class_weights_dict[i] for i in range(len(class_weights))],\n",
    "    'objective': ['multi:softmax']\n",
    "}\n",
    "\n",
    "# Initialize XGBClassifier\n",
    "xgb = XGBClassifier(random_state=42, use_label_encoder=False)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search_xgb = RandomizedSearchCV(estimator=xgb, param_distributions=param_grid, scoring='accuracy', \n",
    "                                       cv=5, n_iter=50, random_state=42, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search_xgb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Best parameters and estimator\n",
    "best_params_xgb = random_search_xgb.best_params_\n",
    "best_estimator_xgb = random_search_xgb.best_estimator_\n",
    "\n",
    "print(f\"Best Parameters (XGBoost): {best_params_xgb}\")\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_xgb = best_estimator_xgb.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print(f\"Accuracy (XGBoost): {accuracy_xgb:.2f}\")\n",
    "\n",
    "print(\"Classification Report (XGBoost):\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f706c829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Parameters (Naive Bayes): {'alpha': 0.1}\n",
      "Accuracy (Naive Bayes): 0.72\n",
      "Classification Report (Naive Bayes):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.03      0.06       125\n",
      "           1       0.00      0.00      0.00        53\n",
      "           2       0.72      0.22      0.34       117\n",
      "           3       0.72      0.98      0.83       698\n",
      "\n",
      "    accuracy                           0.72       993\n",
      "   macro avg       0.47      0.31      0.31       993\n",
      "weighted avg       0.65      0.72      0.63       993\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arjun\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 5 is smaller than n_iter=50. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\arjun\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\arjun\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\arjun\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming the data is preprocessed and loaded into the DataFrame df\n",
    "\n",
    "# Shuffle the dataset\n",
    "df = shuffle(df, random_state=42)\n",
    "\n",
    "# Define features and target variable\n",
    "X = df['ReviewContent']\n",
    "y = df['Sentiment_encoded']\n",
    "\n",
    "# Stratified split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 5.0, 10.0]\n",
    "}\n",
    "\n",
    "# Initialize MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search_nb = RandomizedSearchCV(estimator=nb, param_distributions=param_grid, scoring='accuracy', \n",
    "                                      cv=5, n_iter=50, random_state=42, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search_nb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Best parameters and estimator\n",
    "best_params_nb = random_search_nb.best_params_\n",
    "best_estimator_nb = random_search_nb.best_estimator_\n",
    "\n",
    "print(f\"Best Parameters (Naive Bayes): {best_params_nb}\")\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_nb = best_estimator_nb.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "print(f\"Accuracy (Naive Bayes): {accuracy_nb:.2f}\")\n",
    "\n",
    "print(\"Classification Report (Naive Bayes):\")\n",
    "print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb1bafa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3310 entries, 2202 to 1532\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   ProductTitle        3310 non-null   object\n",
      " 1   ReviewTitle         3310 non-null   object\n",
      " 2   ReviewContent       3310 non-null   object\n",
      " 3   Date                3310 non-null   object\n",
      " 4   Rating              3310 non-null   int64 \n",
      " 5   Author              3310 non-null   object\n",
      " 6   Country             3310 non-null   object\n",
      " 7   Sentiment           3310 non-null   object\n",
      " 8   Category            3310 non-null   object\n",
      " 9   Generation          3310 non-null   object\n",
      " 10  Category_encoded    3310 non-null   int32 \n",
      " 11  Generation_encoded  3310 non-null   int32 \n",
      " 12  Sentiment_encoded   3310 non-null   int32 \n",
      " 13  Country_encoded     3310 non-null   int32 \n",
      "dtypes: int32(4), int64(1), object(9)\n",
      "memory usage: 336.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c574d4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3310x4417 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 67843 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8659b287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1019)\t0.18243286549078838\n",
      "  (0, 2982)\t0.12227289764081505\n",
      "  (0, 1937)\t0.19463781057722396\n",
      "  (0, 3673)\t0.2274251316993977\n",
      "  (0, 1610)\t0.15658954522793309\n",
      "  (0, 1167)\t0.28754503883287036\n",
      "  (0, 3001)\t0.14384228266549226\n",
      "  (0, 1310)\t0.16499612969690822\n",
      "  (0, 3291)\t0.13932136555996386\n",
      "  (0, 2553)\t0.32109485607571264\n",
      "  (0, 1254)\t0.19028696318859564\n",
      "  (0, 3004)\t0.09841468471927833\n",
      "  (0, 1326)\t0.1661158047157613\n",
      "  (0, 2634)\t0.18650300046973692\n",
      "  (0, 1649)\t0.17007484845218182\n",
      "  (0, 1552)\t0.12827254963997017\n",
      "  (0, 1966)\t0.28754503883287036\n",
      "  (0, 3133)\t0.2201375495704517\n",
      "  (0, 2340)\t0.104459321134672\n",
      "  (0, 60)\t0.23222083536821272\n",
      "  (0, 1597)\t0.17936138549749797\n",
      "  (0, 2052)\t0.16089781548652654\n",
      "  (0, 2003)\t0.2297429958099717\n",
      "  (0, 4179)\t0.277213101576822\n",
      "  (0, 3526)\t0.1368950531678342\n",
      "  :\t:\n",
      "  (3304, 2802)\t0.42331590611255965\n",
      "  (3304, 3391)\t0.5326277255781943\n",
      "  (3305, 3161)\t0.1765134844516371\n",
      "  (3305, 975)\t0.3090678047096154\n",
      "  (3305, 2615)\t0.4856644888610353\n",
      "  (3305, 2841)\t0.42563078838211055\n",
      "  (3305, 2947)\t0.5077282554681287\n",
      "  (3305, 3556)\t0.44553399055356463\n",
      "  (3306, 1610)\t0.26828527316166095\n",
      "  (3306, 3001)\t0.24644535521790667\n",
      "  (3306, 4337)\t0.19081890093785508\n",
      "  (3306, 2492)\t0.20531381922447012\n",
      "  (3306, 3161)\t0.14161656773586495\n",
      "  (3306, 4260)\t0.4998366359249766\n",
      "  (3306, 2719)\t0.24423437663893224\n",
      "  (3306, 2228)\t0.24912943172720933\n",
      "  (3306, 3094)\t0.2561812395657242\n",
      "  (3306, 105)\t0.29795935541591945\n",
      "  (3306, 1469)\t0.4926516593254384\n",
      "  (3307, 3004)\t0.6008682913526713\n",
      "  (3307, 1720)\t0.7993480446256946\n",
      "  (3308, 3166)\t0.5880564392311735\n",
      "  (3308, 2802)\t0.8088198960700417\n",
      "  (3309, 3161)\t0.6161932777403232\n",
      "  (3309, 2014)\t0.7875949748872431\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e8263888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1019)\t0.18243286549078838\n",
      "  (0, 2982)\t0.12227289764081505\n",
      "  (0, 1937)\t0.19463781057722396\n",
      "  (0, 3673)\t0.2274251316993977\n",
      "  (0, 1610)\t0.15658954522793309\n",
      "  (0, 1167)\t0.28754503883287036\n",
      "  (0, 3001)\t0.14384228266549226\n",
      "  (0, 1310)\t0.16499612969690822\n",
      "  (0, 3291)\t0.13932136555996386\n",
      "  (0, 2553)\t0.32109485607571264\n",
      "  (0, 1254)\t0.19028696318859564\n",
      "  (0, 3004)\t0.09841468471927833\n",
      "  (0, 1326)\t0.1661158047157613\n",
      "  (0, 2634)\t0.18650300046973692\n",
      "  (0, 1649)\t0.17007484845218182\n",
      "  (0, 1552)\t0.12827254963997017\n",
      "  (0, 1966)\t0.28754503883287036\n",
      "  (0, 3133)\t0.2201375495704517\n",
      "  (0, 2340)\t0.104459321134672\n",
      "  (0, 60)\t0.23222083536821272\n",
      "  (0, 1597)\t0.17936138549749797\n",
      "  (0, 2052)\t0.16089781548652654\n",
      "  (0, 2003)\t0.2297429958099717\n",
      "  (0, 4179)\t0.277213101576822\n",
      "  (0, 3526)\t0.1368950531678342\n",
      "  (0, 3497)\t0.16873626760420443\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_matrix[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f29f48f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1019)\t0.18243286549078838\n",
      "  (0, 2982)\t0.12227289764081505\n",
      "  (0, 1937)\t0.19463781057722396\n",
      "  (0, 3673)\t0.2274251316993977\n",
      "  (0, 1610)\t0.15658954522793309\n",
      "  (0, 1167)\t0.28754503883287036\n",
      "  (0, 3001)\t0.14384228266549226\n",
      "  (0, 1310)\t0.16499612969690822\n",
      "  (0, 3291)\t0.13932136555996386\n",
      "  (0, 2553)\t0.32109485607571264\n",
      "  (0, 1254)\t0.19028696318859564\n",
      "  (0, 3004)\t0.09841468471927833\n",
      "  (0, 1326)\t0.1661158047157613\n",
      "  (0, 2634)\t0.18650300046973692\n",
      "  (0, 1649)\t0.17007484845218182\n",
      "  (0, 1552)\t0.12827254963997017\n",
      "  (0, 1966)\t0.28754503883287036\n",
      "  (0, 3133)\t0.2201375495704517\n",
      "  (0, 2340)\t0.104459321134672\n",
      "  (0, 60)\t0.23222083536821272\n",
      "  (0, 1597)\t0.17936138549749797\n",
      "  (0, 2052)\t0.16089781548652654\n",
      "  (0, 2003)\t0.2297429958099717\n",
      "  (0, 4179)\t0.277213101576822\n",
      "  (0, 3526)\t0.1368950531678342\n",
      "  (0, 3497)\t0.16873626760420443\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6541ae22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
