# -*- coding: utf-8 -*-
"""XGBOOST-RandomizedSearchCV.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/155shg7yD8zXaVBVuuYRprXd3_Ou8fBCP

*assuming necessary libraries are imported

XGBoost RANDOMIZED SERACH CV
"""

import xgboost as xgb

# Convert data to DMatrix format for XGBoost
dtrain = xgb.DMatrix(X_train, label=y_train)
dtest = xgb.DMatrix(X_test, label=y_test)

# Define parameters for XGBoost
param_grid_xgb = {
    'max_depth': [3, 4, 5, 6, 8, 10],
    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],
    'n_estimators': [100, 200, 300, 400],
    'colsample_bytree': [0.3, 0.4, 0.5, 0.7, 0.8, 1.0],
    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0]
}

# Perform RandomizedSearchCV with XGBoost
xgb_random_search = RandomizedSearchCV(estimator=xgb.XGBClassifier(objective="multi:softmax", num_class=4, seed=42),
                                       param_distributions=param_grid_xgb, n_iter=50,
                                       scoring='accuracy', n_jobs=-1, cv=5, verbose=1, random_state=42)
xgb_random_search.fit(X_train, y_train)

# Get the best model and evaluate on test set
best_xgb = xgb_random_search.best_estimator_
y_pred_xgb = best_xgb.predict(X_test)

# Print best parameters and classification report
print("Best Parameters (XGBoost):", xgb_random_search.best_params_)
print("Accuracy (XGBoost):", xgb_random_search.best_score_)
print("Classification Report (XGBoost):")
print(classification_report(y_test, y_pred_xgb))